diff --git a/Python/ceval_gil.h b/Python/ceval_gil.h
index a3b450bd5c..30bebc418c 100644
--- a/Python/ceval_gil.h
+++ b/Python/ceval_gil.h
@@ -4,6 +4,7 @@
 
 #include <stdlib.h>
 #include <errno.h>
+#include <pthread.h>
 
 
 /* First some general settings */
@@ -102,7 +103,21 @@ static unsigned long gil_interval = DEFAULT_INTERVAL;
             timeout_result = 0; \
     } \
 
+/* For GIL logging */
+#define MAXHISTORY 5000000
+static int           thread_history[MAXHISTORY];
+static unsigned char thread_acquire[MAXHISTORY];
+static int           switch_history[MAXHISTORY];
+static double        time_history[MAXHISTORY];
+static unsigned int  history_count = 0;
 
+#define EVENT_ENTRY           0
+#define EVENT_ACQUIRE         1
+#define EVENT_RELEASE         2
+#define EVENT_GIL_CREATE      3
+#define EVENT_REQUEST_RELEASE 4
+
+static char *_codes[] = {"ENTRY", "ACQUIRE", "RELEASE", "CREATE", "REQUEST"};
 
 /* Whether the GIL is already taken (-1 if uninitialized). This is atomic
    because it can be read without any lock taken in ceval.c. */
@@ -126,6 +141,40 @@ static COND_T switch_cond;
 static MUTEX_T switch_mutex;
 #endif
 
+static void print_history(void) {
+    int i;
+    FILE *f;
+
+    f = fopen("history3.6.txt", "w");
+    for (i = 0; i < history_count; i++) {
+        fprintf(f,"%x %s %0.6f\n", thread_history[i], _codes[thread_acquire[i]], time_history[i]);
+    }
+    fclose(f);
+}
+
+static int log_history(int start_thread, int event, int get_tz) {
+    if (history_count < MAXHISTORY) {
+        thread_history[history_count] = start_thread;
+        
+        if(get_tz) {
+            {
+                struct timeval t;
+#ifdef GETTIMEOFDAY_NO_TZ
+            if (gettimeofday(&t) == 0)
+        time_history[history_count] = (double)t.tv_sec + t.tv_usec*0.000001;
+#else /* !GETTIMEOFDAY_NO_TZ */
+            if (gettimeofday(&t, (struct timezone *)NULL) == 0)
+            time_history[history_count] = (double)t.tv_sec + t.tv_usec*0.000001;
+#endif /* !gettimeofday_no_tz */
+            }
+        } else {
+            time_history[history_count] = 0.0;
+        }
+        thread_acquire[history_count++] = event;
+        return 1;
+    }
+    return 0;
+}
 
 static int gil_created(void)
 {
@@ -166,6 +215,8 @@ static void recreate_gil(void)
 {
     _Py_ANNOTATE_RWLOCK_DESTROY(&gil_locked);
     /* XXX should we destroy the old OS resources here? */
+
+    log_history((int) pthread_self(), EVENT_GIL_CREATE, 0);
     create_gil();
 }
 
@@ -180,6 +231,7 @@ static void drop_gil(PyThreadState *tstate)
            holder variable so that our heuristics work. */
         _Py_atomic_store_relaxed(&gil_last_holder, (uintptr_t)tstate);
     }
+    log_history((int) pthread_self(), EVENT_RELEASE, 0);
 
     MUTEX_LOCK(gil_mutex);
     _Py_ANNOTATE_RWLOCK_RELEASED(&gil_locked, /*is_write=*/1);
@@ -213,6 +265,8 @@ static void take_gil(PyThreadState *tstate)
     err = errno;
     MUTEX_LOCK(gil_mutex);
 
+    log_history((int) pthread_self(), EVENT_ENTRY, 0);
+
     if (!_Py_atomic_load_relaxed(&gil_locked))
         goto _ready;
 
@@ -227,6 +281,7 @@ static void take_gil(PyThreadState *tstate)
         if (timed_out &&
             _Py_atomic_load_relaxed(&gil_locked) &&
             gil_switch_number == saved_switchnum) {
+            log_history((int) pthread_self(), EVENT_REQUEST_RELEASE, 0);
             SET_GIL_DROP_REQUEST();
         }
     }
@@ -239,6 +294,8 @@ _ready:
     _Py_atomic_store_relaxed(&gil_locked, 1);
     _Py_ANNOTATE_RWLOCK_ACQUIRED(&gil_locked, /*is_write=*/1);
 
+    log_history((int) pthread_self(), EVENT_ACQUIRE, 0);
+
     if (tstate != (PyThreadState*)_Py_atomic_load_relaxed(&gil_last_holder)) {
         _Py_atomic_store_relaxed(&gil_last_holder, (uintptr_t)tstate);
         ++gil_switch_number;
